{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Notes 数据科学笔记\n",
    "\n",
    "## 1. Introduction 介绍\n",
    "\n",
    "### 1.1 Data and Dataset 数据与数据集\n",
    "\n",
    "#### 1.1.1 What is Data? 什么是数据？\n",
    "Data refers to facts, statistics, or values that convey information. It can be structured (tables, databases) or unstructured (slides, documentation).  \n",
    "数据是事实、统计数据或数值，能够传达信息，可以是**结构化**（表格、数据库）或**非结构化**（幻灯片、文档）。\n",
    "\n",
    "#### 1.1.2 What is a Dataset? 什么是数据集？\n",
    "A dataset consists of rows and columns:  \n",
    "数据集由行和列组成：\n",
    "- **Rows (observations, 观察值)**: Represent individual cases or instances (e.g., each customer in a dataset).  \n",
    "- **Columns (variables, 变量)**: Represent features describing the observations.\n",
    "\n",
    "#### 1.1.3 Types of Data 数据类型\n",
    "- **Categorical (分类数据)**: Data divided into distinct groups (e.g., colors, cities).  \n",
    "- **Numerical (数值数据)**: Data expressed as numbers (e.g., age, temperature).\n",
    "\n",
    "#### 1.1.4 Levels of Measurement 测量水平\n",
    "- **Nominal (名义变量)**: Categories without a meaningful order (e.g., gender, country).  像标签一样，只用来区分不同类别，没有任何顺序（类别间无高低大小关系）或数值（不能进行数学运算）意义。可以使用频数、百分比，众数，不能使用加减乘除、中位数、平均差，标准差。\n",
    "- **Ordinal (序数变量)**: Ordered categories without meaningful differences (e.g., satisfaction levels). 数据有类别，也有顺序，但互相之间的差距没有数值意义。比如比赛名次，无法判断第一名与第五名之间究竟差多少。可使用排序、频数、百分比、众数、中位数，不能使用均值、标准差和加减乘除。\n",
    "- **Interval (区间变量)**: Ordered categories with meaningful differences but no true zero (e.g., temperature in Celsius).  数据有顺序，类别之间的差距也有数值意义，但只能加减不能乘除，因为区间变量的零是一个认为定的点。比如楼层，2层不是1层的2倍；比如时间，6点不是3点的2倍。可用除了倍数以外的几乎所有的统计方法。\n",
    "- **Ratio (比率变量)**: Like interval data but with a true zero (e.g., height, weight). 数据有顺序，差距有意义，存在真正的零点。比如年龄，10岁是5岁的2倍；比如钱，100元是50元的2倍。适用几乎所有的统计方法，包括倍数比较。\n",
    "![测量水平](img\\levels-of-measurement.png)\n",
    "\n",
    "### 1.2 CRISP-DM (Cross Industry Standard Process for Data Mining) 数据挖掘标准流程\n",
    "A structured framework for conducting data science projects.  \n",
    "用于执行数据科学项目的标准框架：\n",
    "1. **Business Understanding (业务理解)** - Define the project goal and understand business needs.\n",
    "2. **Data Understanding (数据理解)** - Explore, visualize, and analyze data.\n",
    "3. **Data Preparation (数据准备)** - Clean and transform data.\n",
    "4. **Modeling (建模)** - Develop predictive models.\n",
    "5. **Evaluation (评估)** - Assess model performance.\n",
    "6. **Deployment (部署)** - Implement the model in a real-world scenario.\n",
    "\n",
    "## 2. Business Understanding 业务理解\n",
    "- **Business Objective (商业目标)**: Understanding what the organization aims to achieve. 业务目标是 公司高层希望实现的目标，通常与业务增长、用户满意度、市场竞争力等有关。比如提高用户满意度、增加订阅用户，提高电影推荐的精准度。例：We aim to only offer the most popular movies and series to our clients, to optimize service satisfaction.\n",
    "- **Business Objective Success Criterion（业务成功标准）**：业务成功标准是 判断业务目标是否达成的标准，通常用 关键绩效指标（KPI） 来衡量。比如用户留存率、流失率降低，付费订阅率提升。例：Our goal is to increase customer satisfaction by 10% within the next year.\n",
    "- **Data Mining Goal (数据挖掘目标)**: Define what data scientists can do to support business objectives. 数据挖掘目标是 数据科学团队 设定的 分析或建模目标，通常涉及 机器学习、预测模型、聚类、推荐系统等。比如开发推荐系统、预测电影的受欢迎程度，识别用户群体。例：We will use machine learning models to predict which movies will be the most popular.\n",
    "- **Data Mining Success Criterion (数据挖掘成功标准)**: 数据挖掘成功标准是 衡量数据挖掘任务是否成功的标准，通常涉及模型性能指标。比如准确率、MSE，召回率。例：Our predictive model achieves an accuracy of 90% in forecasting the popularity of a movie.\n",
    "<br>\n",
    "数据挖掘目标通常是从业务目标衍生出来的，为业务提供数据支持，最终目的是支持业务决策。业务目标决定数据挖掘的方向和方法。数据挖掘目标应该与业务目标保持一致，以确保分析有意义且相关。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Data Understanding 数据理解\n",
    "\n",
    "### 3.1 Descriptive Statistics 描述性统计\n",
    "#### Central Tendency 中心趋势\n",
    "- **Mean (均值)**: Uses all data points but **sensitive to outliers**. 平均值用到了所有数据点，能反映整体水平，但需要小心极端值。\n",
    "- **Median (中位数)**: Robust to outliers.中位数是排序后找到中间那个值，因此对异常值不敏感，它可以找出最“稳妥”的中间值。\n",
    "- **Mode (众数)**: Useful for categorical data. 众数是找出现次数最多的值，因此不需要数值也能用，可以用它看最常见的类别。\n",
    "\n",
    "#### Variability 变异性\n",
    "- **Variance (方差, σ²)**: Measures spread of data 衡量数据的离散程度；方差反映了数据偏离均值的程度，数值越大，数据越分散（即最大值和最小值的距离较大）。\n",
    "  1. 计算数据点与均值的差异；\n",
    "  2. 平方并求平均值（即方差）。\n",
    "- **Standard Deviation (标准差, σ)**: Square root of variance 方差的平方根，表示数据点偏离均值的程度。\n",
    "  - **标准差较低** → 数据集中在均值附近，即数据之间差异不大。\n",
    "  - **标准差较高** → 数据分布更分散，即数据之间差异较大。\n",
    "\n",
    "### 3.2 Outliers 异常值\n",
    "- **Detection Methods:** \n",
    "  - Z-score：适用于正态分布。Z = (x - 均值) / 标准差，表示一个数据点偏离均值多少个标准差。通常Z-score > 3 或 < -3 被认为是异常值。\n",
    "  - IQR：适用于偏态分布。Q1 = 第25百分位，Q3 = 第75百分位，IQR = Q3 - Q1。异常值范围: < Q1 - 1.5×IQR 或 > Q3 + 1.5×IQR。\n",
    "  - Boxplot(箱线图)：适合任何分布。用图形展示IQR方法的结果，超出上下限的点即为异常值。\n",
    "- **Handling:** \n",
    "  - 直接删除超出阈值的行；\n",
    "  - 使用均值（适用于数据较稳定时）或中位数（适用于受异常值影响较大的数据）替换异常值；\n",
    "\n",
    "### 3.3 Distributions 分布\n",
    "数据点在不同范围内的集中或分散情况。\n",
    "#### 3.3.1 Normal Distribution 正态分布\n",
    "- 呈 **对称钟形曲线**，中间高，两边低。\n",
    "- 特点：**均值 = 中位数 = 众数**。\n",
    "- 68-95-99.7规则：约 **68%**数据落在 **均值 ± 1个标准差** 之间，**95%** 落在 **均值 ± 2个标准差** 之间，**99.7%** 落在 **均值 ± 3个标准差** 之间。\n",
    "\n",
    "#### 3.3.2 Skewed Distribution 偏态分布\n",
    "- **非对称分布**，均值、中位数、众数不再相等，它们的相对位置展示了数据偏向哪一边。\n",
    "- **正偏态 (右偏, Positive Skew)**: 左边陡峭，右边有个长尾巴，**均值 > 中位数 > 众数**。\n",
    "- **负偏态 (左偏, Negative Skew)**: 右边陡峭，左边有个长尾巴，**均值 < 中位数 < 众数**。\n",
    "\n",
    "\n",
    "### 3.4 Correlation 相关性分析\n",
    "**Measures the strength and direction of relationships between two variables**\n",
    "- Values range from -1 to +1: \n",
    "  - Positive correlation (+)，比如身高和体重；+1 完全正相关，表示一个变量增加另一个也增加；\n",
    "  - Negative correlation (-)，比如学习时间和错题率；-1 完全负相关，表示一个变量增加另一个减少；\n",
    "  - No correlation (≈ 0)，比如鞋码和智商；0 无相关性，表示两个变量没什么关系。\n",
    "- **Correlation 相关性 ≠ Causation 因果关系**：冰淇凌销量和溺水事件正相关，但不是冰淇凌导致溺水，而是夏天高温而同时增加了两者。相关性只说明有关联，不代表谁导致谁。\n",
    "\n",
    "#### 3.4.1 Pearson Correlation (皮尔逊相关系数)\n",
    "- Measures **linear** relationships. 衡量两个变量之间的线性关系。\n",
    "- **Assumptions:** Linear relationship, continuous variables（不是类别数据）, no significant outliers, normal distribution (for hypothesis testing).\n",
    "- **Strength Interpretation Guidelines:**（负值也是一样，只是方向相反）\n",
    "  - 0.00-0.19: Very weak\n",
    "  - 0.20-0.39: Weak\n",
    "  - 0.40-0.59: Moderate\n",
    "  - 0.60-0.79: Strong\n",
    "  - 0.80-1.00: Very strong\n",
    "- **Statistical Significance 统计显著性:**（计算完相关系数后，还要用P值来判断它是否可信）\n",
    "  - p-value < 0.05: Significant (5% chance of false positive)\n",
    "  - p-value < 0.01: Highly significant (1% chance of false positive)\n",
    "  - p-value < 0.001: Very highly significant (0.1% chance of false positive)\n",
    "<br>\n",
    "Pearson只关心具体数值，使用精确的线性分析。<br>\n",
    "如果散点图是直线，系数高；如果是曲线，系数低。\n",
    "\n",
    "#### 3.4.2 Spearman’s Rank (斯皮尔曼秩相关系数)\n",
    "- Measures **monotonic** relationships (both linear and non-linear).衡量两个变量之间的单调关系，不一定是线性的，看的是单调趋势。因为它的计算方法是将数据先排列，然后算排名的相关性。\n",
    "- 特点：①适用于单调关系，包括非线性；②因为是用排名，所以对异常值不敏感；③无需假设正态分布。\n",
    "- 参考范围：同Pearson的强度划分一样。<br>\n",
    "<br>\n",
    "Spearman只看顺序，适合排名或趋势分析。<br>\n",
    "如果一个变量涨，另一个变量也涨（或跌）；系数高，不在乎幅度。<br><br>\n",
    "\n",
    "|特性|Pearson皮尔逊|Spearman斯皮尔曼|\n",
    "|--|--|--|\n",
    "|关系类型|线性|单调（线性或非线性）|\n",
    "|数据类型|连续变量|连续或序数变量|\n",
    "|分布要求|最好是正态分布|无分布要求|\n",
    "|异常值影响|敏感|不敏感|\n",
    "|例子|身高和体重|学习时间和考试排名|\n",
    "\n",
    "#### 3.4.3 Correlation Matrices (相关矩阵) & Heatmaps (热图)\n",
    "**Visualize relationships between variables.**<br><br>\n",
    "\n",
    "相关矩阵：是一个表格，显示多个变量之间的相关系数，系数范围-1到1；对角线上的数字是变量与自己的相关性，总是1。<br>\n",
    "热图：是相关矩阵的“彩色版”，用颜色表示相关系数的大小；颜色越深，相关性越强。<br><br>\n",
    "\n",
    "**Feature Redundancy (特征冗余)**: Identify highly correlated features to reduce model complexity.<br>\n",
    "如果两个变量高度相关，比如相关系数>8或<-0.8，它们提供的信息可能重复。保留太多冗余特征会增加模型的复杂性而不提升其效果，可考虑去掉一个。<br><br>\n",
    "\n",
    "**Multicollinearity (多重共线性)**: When features are too correlated, it can affect model performance.<br>\n",
    "当多个变量之间高度相关，会干扰某些模型（比如线性回归）的性能，因为模型无法判断/区分哪个变量真正起了作用。识别多重共线性，可避免模型过拟合或不正确。\n",
    "\n",
    "### 3.5 Data Visualization 数据可视化\n",
    "可视化的作用：\n",
    "- **揭示模式、趋势和相关性**（Reveal patterns, trends, and correlations）。  \n",
    "- **对大型数据集进行可视化总结**（Visually summarize large datasets）。  \n",
    "- **识别异常值或离群点**（Identify outliers or anomalies）。  \n",
    "- **有效传达研究发现**（Help communicate findings effectively）。\n",
    "\n",
    "#### 3.5.1 常见数据可视化方法\n",
    "- **Histogram (直方图)**: Displays numerical distributions.\n",
    "- **Bar Plot (条形图)**: Compares categorical values.\n",
    "- **Scatter Plot (散点图)**: Shows relationships between numerical variables.\n",
    "- **Line Graph (折线图)**: Tracks changes over time.\n",
    "\n",
    "注意：所有图都是将特征变量（自变量，Independent Variable）放在x轴，目标变量（因变量，Dependent Variable）放在y轴，以方便观察特征对目标的影响。<br>\n",
    "\n",
    "| 图表类型 | 适用数据类型 | 作用 |\n",
    "|----------|------------|------|\n",
    "| **直方图 (Histogram)** | 数值数据 | 查看数值分布（如身高是否呈正态分布）。数据分入不同区间（Bins），柱子代表该区间的数据数量（频率），柱子无间隔（连续）。 |\n",
    "| **条形图 (Bar Plot)** | 分类数据 | 比较不同类别的计数或均值（如各年龄段人数）。柱子之间有间隔（分离）。 |\n",
    "| **散点图 (Scatter Plot)** | 两个数值变量 | 观察变量之间的关系（如身高与体重的关系），用于识别相关性、聚类或趋势。 |\n",
    "| **折线图 (Line Graph)** | 时间序列或有序类别 | 跟踪随时间变化的趋势（如体重随年龄变化），适用于比较多个数据集。 |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Data Preparation 数据准备\n",
    "让数据干净、可靠、适合后续使用。\n",
    "### 4.1 Data Cleaning 数据清理\n",
    "数据清理的目标是让数据“完整”和“一致”。\n",
    "- **Typos (拼写错误):** 用 `.unique()` 查看变量的所有唯一值，找出拼写问题，用 `.replace()` 替换错误值。\n",
    "- **Duplicates 重复项**：用`df.duplicated()`和`df[df.duplicated()]`检查；用`df=df.drop_duplicated()`删除。\n",
    "- **Handling Missing Values (处理缺失值):**数据中有些值可能是空的（NaN）\n",
    "  - **Forward Fill (正向填充, ffill)**: Fills missing values with the last observed value. 适用于数据有连续性时，比如温度记录。\n",
    "  - **Backward Fill (反向填充, bfill)**: Fills missing values with the next observed value. 适用于数据趋势向后延续时。\n",
    "  - **Mean/Median Imputation (均值/中位数填充)**: 适用于数值数据，尤其是分布均匀时（中位数对偏态数据更好）。\n",
    "- **Impact of Missing Data (缺失数据的影响)**: Can introduce bias（比如用均值填充偏态数据会拉低结果） and reduce model accuracy（如果直接删除缺失行，会减少样本量，影响模型准确性）.<br><br>\n",
    "\n",
    "**缺失类型**：<br>\n",
    "- Missing Completely At Random (MCAR) 完全随机缺失：数据的缺失与任何变量都无关；它不会引入偏差；可直接删除或使用均值填充，不会影响分析结果。\n",
    "- Missing At Random (MAR) 随机缺失: 数据的缺失与其他已观测变量有关，但与该变量本身的真实值无关；它会引入偏差；可用其他已观测变量预测缺失值并填充。\n",
    "- Missing Not At Random (MNAR) 非随机缺失: 数据的缺失与该变量本身的真实值有关；严重引入偏差；很难调整，需要复杂建模或收集更多数据。\n",
    "\n",
    "**处理缺失值**：<br>\n",
    "- 删除（适用于缺失数据较少的情况）：1. `df.dropna(inplace=True)` 删除包含 NaN 的行； 2. `df.drop(columns=['column_name'], inplace=True)` 删除缺失值多的列\n",
    "- 填充：1. `df['column'].fillna(df['column'].mean(), inplace=True)` 使用均值填充，适用于数据分布较均匀的情况；2. `df['column'].fillna(df['column'].median(), inplace=True)` 使用中位数填充，适用于偏态数据；3. 使用众数填充（mode），适用于分类数据；4. 使用前后值填充（ffill/bfill），适用于时间序列数据。\n",
    "\n",
    "### 4.2 Independence & Representativity 独立性 & 代表性\n",
    "- **Independence (独立性)**: Each observation should not influence another. 据点（行）或特征（列）之间互不影响。不独立会导致模型偏倚或过拟合，可以尝试删除重复行。\n",
    "  - 因变量（Dependent Variable，目标变量）：想要预测的变量。\n",
    "  - 自变量（Independent Variable，特征变量）：用于预测因变量的输入变量，即 模型的特征（features）。\n",
    "- **Representativity (代表性)**: Ensure dataset reflects the broader population. 数据应当反映目标总体。可以检查模型是否有缺失子群体、分布不匹配或特征选择偏差的问题。缺乏代表性会造成偏见，应当按比例采样、加权、补充数据。\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Modeling 建模\n",
    "\n",
    "### 5.1 Benchmark Models 基准模型\n",
    "- **Baseline comparison (基准比较)**: Helps measure improvement from complex models. 分类问题全猜“否”，回归问题直接用均值或众数。基准模型是一个简单、容易理解的模型，用它来作为起点，衡量更复杂模型的表现。\n",
    "\n",
    "### 5.2 Training & Testing 训练与测试\n",
    "评估模型在未见过数据上的表现。\n",
    "- **Train-Test Split (训练-测试拆分)**: Common splits (70%-30%, 80%-20%). 数据分 训练集（发现模式）和 测试集（检查泛化）。训练集指标应该大于测试集指标。\n",
    "- **Cross-validation (交叉验证)**: K-fold validation to assess model generalizability. 数据分 K 份（常见 K = 5 或 10），比如数据 100 条，K = 5，每份 20 条。第 1 次用 1-20 测试，21-100 训练；第 2 次用 21-40 测试，1-20 和 41-100 训练。最后平均 5 次的准确率，得到模型的泛化能力评估。\n",
    "\n",
    "### 5.3 Regression & Classification 回归与分类\n",
    "#### Regression Model (回归模型)\n",
    "回归模型用于预测连续数值变量（如房价、气温）。其核心目标是找到输入特征与输出变量之间的映射关系。<br>\n",
    "\n",
    "创建步骤：处理缺失值、异常值、特征选择和工程、数据集划分、选择合适的回归算法、训练模型并调整超参数、计算误差<br>\n",
    "\n",
    "**Linear Regression (线性回归)**: 适用于线性关系、连续数据，它的可解释性强、计算高效，但需要假设线性关系，并且对异常值敏感。<br>\n",
    "当线性回归的线性假设被违反时，可以考虑进行进行特征变换，或换成不需要线性假设的模型（比如决策树）。<br>\n",
    "\n",
    "#### Classification Model (分类模型)\n",
    "分类模型用于预测离散类别标签（如垃圾邮件分类、肿瘤类型判断）。目标是找到数据输入与类别输出的对应关系。<br>\n",
    "\n",
    "创建步骤：和回归模型一样，只是需要选择合适的分类算法。<br>\n",
    "\n",
    "**Decision Trees (决策树)**: Uses feature-based splits. 基于特征划分数据，适用于非线性关系和类别数据。递归生成子节点，直到满足停止条件。<br>\n",
    "\n",
    "特点：适用于非线性关系、类别数据，它易解释、可处理非线性，但是容易过拟合，对数据敏感。<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Model Evaluation 模型评估\n",
    "模型评估是检查模型好坏的关键，回归和分类有不同的指标。\n",
    "\n",
    "### 6.1 Regression Metrics 回归指标\n",
    "回归模型预测连续值（如房价、温度），评估指标关注预测值和真实值的差距。\n",
    "- **MAE (平均绝对误差)**: Measures average error. 把每个预测值和真实值的差（不管正负，先取绝对值）加起来，再除以总个数。适用于数据里有异常值时，因为MAE只关心整体的平均误差。\n",
    "- **MSE (均方误差)**: Penalizes large errors. 把每个预测值和真实值的差平方（放大误差），加起来，再除以总个数。因为用了平方，大误差会被放大。不适合异常值多的场景。\n",
    "- **RMSE (均方根误差)**: Square root of MSE. 先算 MSE，然后开平方，回到和原始数据一样的单位。它比 MAE 更敏感，更关注大误差。\n",
    "- **R² (决定系数)**: Measures how well the model explains variance in the target. 用 1 减去“模型误差（预测值和真实值的差平方加起来）除以基准误差（真实值和平均值的差平方加起来）”的结果。评估模型解释目标变量方差的能力，取值范围通常在 0 到 1（可能为负），越大越好。R2=0.9: 模型解释了 90% 的房价变化，很不错；𝑅2=0: 模型和简单猜均值一样，没用。\n",
    "\n",
    "优化:<br>\n",
    "特征选择（相关性分析、前向/后向选择）。<br>\n",
    "处理多重共线性（移除高度相关特征）。<br>\n",
    "特征工程（非线性关系转换）。\n",
    "\n",
    "**Ordinary Least Squares (普通最小二乘法, OLS)**: Minimizes the sum of squared residuals. 通过最小化残差平方和来优化模型。OLS 是线性回归的核心方法，目标是找到一条直线（比如 y=a+bX），让预测值和真实值的差平方和最小。过程：假设一个直线关系（比如房价和面积），计算每个点的预测值和真实值的差，平方后加起来。调整直线的斜率 b 和截距 a，让这个总误差最小。它可以提供一个基准线性模型，其他指标（R 2, MAE 等）基于它评估。\n",
    "\n",
    "### 6.2 Classification Metrics 分类指标\n",
    "像一个成绩单，告诉你模型在正类和负类上哪里做对了，哪里错了。\n",
    "- **Confusion Matrix (混淆矩阵)**:\n",
    "  - **True Positive (TP, 真阳性)**: Correctly predicted positive cases.\n",
    "  - **True Negative (TN, 真阴性)**: Correctly predicted negative cases.\n",
    "  - **False Positive (FP, 假阳性)**: Incorrectly predicted positive cases.\n",
    "  - **False Negative (FN, 假阴性)**: Incorrectly predicted negative cases.\n",
    "\n",
    "例: 癌症检测共1000 人。<br>\n",
    "TP = 80（找到80 个病人，且他们确实有病）。<br>\n",
    "TN = 900（找到900 个健康人，且他们确实没病）。<br>\n",
    "FP = 20（有20 个健康人被误诊为有病）。<br>\n",
    "FN = 10（有10 个病人被误诊为没病）。<br>\n",
    "\n",
    "- **Accuracy (准确率)**: 正确预测的（TP + TN）除以总数，如(80 + 900) / 1000 = 0.98。用来看模型的整体表现。\n",
    "- **Precision (精确率)**: TP / (TP + FP)，如80 / (80 + 20) = 0.8。用来看模型预测正类的准度。\n",
    "- **Recall (召回率)**: TP / (TP + FN)，如80 / (80 + 10) = 0.89。用来看模型是否找全了正类。\n",
    "- **F1 Score**: 精确率和召回率的平衡值（2 × (Precision × Recall) / (Precision + Recall)），如2 × (0.8 × 0.89) / (0.8 + 0.89) ≈ 0.84。\n",
    "\n",
    "优化：<br>\n",
    "高准确率 + 低召回率: 模型偏负类，漏掉正类。<br>\n",
    "高精确率 + 低召回率: 正类预测准但少。<br>\n",
    "高召回率 + 低精确率: 正类找得多但误报多。<br>\n",
    "\n",
    "**Overfitting (过拟合)**: <br>\n",
    "When a model learns training data too well and fails to generalize. 训练集准确率高但测试集准确率低，树结构过于复杂。<br>\n",
    "当发现过拟合情况时，应apply pruning techniques（剪枝技术） or adjust hyperparameters（超参数）。<br>\n",
    "可以通过控制最大深度（限制深度，防止树过度复杂）、最大特征数（max_features，限制每次分裂可选的特征数量）、最小分割样本数（min_samples_split，只有当样本数足够时才允许分裂）和最小叶节点样本数（min_samples_leaf，叶子节点必须至少包含一定数量的样本，否则不会继续分裂）来解决。<br>\n",
    "最小分割样本数决定树是否分裂，控制树的生长速度；最小叶节点样本数决定叶子里最终至少要有多少数据，控制树的稳定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
