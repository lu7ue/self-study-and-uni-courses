{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pratical Usage\n",
    "## 1. Basic Knowledge of Python\n",
    "### 1.1 Comments\n",
    "**Single-line comments**: Use `#` to add a comment.<br>\n",
    "**Multi-line comments**: Use triple quotes `'''` or `\"\"\"` around the comment.\n",
    "```python\n",
    "# This is a single line comment. Use the \"pound\" sign, or \"hashtag\"\n",
    "\n",
    "\"\"\"\n",
    "This is a multiline comment. \n",
    "These comments go *in* a function, \n",
    "instead of *above* when you use them as function documentation.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 1.2 Variables\n",
    "A variable name is case-sensitive and starts with a letter or underscore. You can use numbers, as long as you don't start with it.\n",
    "<br>\n",
    "The snake case technique is widely used for variable names, where each word is seperated by an underscore.\n",
    "<br>\n",
    "It's not possible to use a Python keyword as a variable name, such as `and`, `class`, `else`, `except`, `import`, [and many more](https://www.w3schools.com/python/python_ref_keywords.asp). \n",
    "\n",
    "### 1.3 Data Types\n",
    "```python\n",
    "x = 1.001\n",
    "y = -100\n",
    "text = \"Don't worry, this won't raise any errors\"\n",
    "boolean = True\n",
    "\n",
    "print(type(x)) # <class 'float'>\n",
    "print(type(y)) # <class 'int'>\n",
    "print(type(text)) # <class 'str'>\n",
    "print(type(boolean)) # <class 'bool'>\n",
    "```\n",
    "\n",
    "### 1.4 Operators\n",
    "#### 1.4.1 Arithmetic operators\n",
    "Here's some basic arithmetic that Python can do:\n",
    "- **Addition**: `+`\n",
    "- **Subtraction**: `-`\n",
    "- **Multiplication**: `*`\n",
    "- **Division**: `/`\n",
    "- **Integer Division**: `//`\n",
    "- **Modulus**: `%`\n",
    "- **Exponentiation**: `**`\n",
    "\n",
    "#### 1.4.2 Comparison operators\n",
    "These help you to compare values. They return a boolean. \n",
    "- **Equal to**: `==`\n",
    "- **Not equal to**: `!=`\n",
    "- **Greater than**: `>`\n",
    "- **Less than**: `<`\n",
    "- **Greater than or equal to**: `>=`\n",
    "- **Less than or equal to**: `<=`\n",
    "\n",
    "#### 1.4.3 Logical operators\n",
    "These are used to combine conditional statements `and`, `or` & `not` \n",
    "\n",
    "### 1.5 Conditions & Loops\n",
    "#### 1.5.1 Conditions\n",
    "Conditional statements allow your code to take different actions based on certain conditions. \n",
    "<br>\n",
    "The most common are `if`, `elif`, and `else`. \n",
    "\n",
    "```python\n",
    "temperature = 25\n",
    "\n",
    "if temperature > 30:\n",
    "    print(\"Wow, tropical day!\")\n",
    "elif temperature > 20:\n",
    "    print(\"It's a nice day.\")\n",
    "elif temperature > 15:\n",
    "    print(\"It's not a bad day.\")\n",
    "else:\n",
    "    print(\"It's a bit chilly.\")\n",
    "\n",
    "# It's a nice day.\n",
    "```\n",
    "\n",
    "#### 1.5.2 Loops\n",
    "Python understands `for` loops and `while` loops just like any other language. The for-loop in Python tends to be used as a foreach-loop.<br>\n",
    "The range (start,end) function returns a list of numbers from `start` to `end - 1`.\n",
    "```python\n",
    "# for loop\n",
    "for i in range(10):\n",
    "    print(i) # 0 1 2 3 4 5 6 7 8 9\n",
    "```\n",
    "```python\n",
    "# while loop\n",
    "i = 0\n",
    "while i < 10:\n",
    "    print(i) # 0 1 2 3 4 5 6 7 8 9\n",
    "    i += 1\n",
    "```\n",
    "\n",
    "### 1.6 Functions\n",
    "Functions can have default parameter values, which are used if no argument is passed during the function call.\n",
    "```python\n",
    "def greet_user(name=\"stranger\", planet=\"Earth\"):\n",
    "    print(f\"Hello, {name}. Welcome to {planet}!\")\n",
    "\n",
    "# Default argument\n",
    "greet_user() # Hello, stranger. Welcome to Earth!\n",
    "\n",
    "# Specified argument\n",
    "greet_user(name=\"Alice\", planet=\"Mars\") # Hello, Alice. Welcome to Mars!\n",
    "```\n",
    "\n",
    "### 1.7 Lists and Dictionaries\n",
    "#### 1.7.1 List\n",
    "A list is an ordered collection of items stored in a single variable. The order is defined and new items are placed at the end. list can be indexed, starting at `[0]`. While a list allows different datatypes, it's questionable whether this is useful to do. A list is created using `[]`.\n",
    "```python\n",
    "flowers = [\"Iris\", \"Poppy\", \"Rose\", \"Iris\"]\n",
    "grades = [5, 6.6, 4, 10]\n",
    "```\n",
    "\n",
    "#### 1.7.1 Dictionaries\n",
    "Note that since a dictionary is a hashtable, it is incredibly quick for calculations. Whereas in Php you would use arrays for everything, in Python you should keep in mind that dictionaries are about 1000 times faster compared to lists.<br>\n",
    "`If order is important and index matters --> list. Any other case --> dictionary.`\n",
    "```python\n",
    "flower_info = {\n",
    "    \"Rose\": {\n",
    "        \"Common Color\": \"Red\",\n",
    "        \"Texture\": \"Velvety\",\n",
    "        \"Scent\": \"Fragrant\",\n",
    "        \"Cultural Significance\": \"Love and Romance\"\n",
    "    },\n",
    "    \"Lily\": {\n",
    "        \"Common Color\": \"White\",\n",
    "        \"Texture\": \"Smooth\",\n",
    "        \"Scent\": \"Sweet\",\n",
    "        \"Cultural Significance\": \"Purity and renewal\"\n",
    "    },\n",
    "    \"Lotus\": {\n",
    "        \"Common Color\": \"Pink\",\n",
    "        \"Texture\": \"Waxy\",\n",
    "        \"Scent\": \"Mild\",\n",
    "        \"Cultural Significance\": \"Spiritual Enlightenment\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## 2. Get Data\n",
    "Pandas is [well-documented](https://pandas.pydata.org/docs/) and one of Python's most used libraries in the data science field.\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "The dataset we will be using is the [Video Games Sales Dataset](https://www.kaggle.com/sidtwr/videogames-sales-dataset), the [.csv file for all video games](https://www.kaggle.com/sidtwr/videogames-sales-dataset?select=Video_Games_Sales_as_at_22_Dec_2016.csv) to be precise.\n",
    "\n",
    "### 2.1 Load and Read File\n",
    "```python\n",
    "df = pd.read_csv('../videogames.csv',sep=';')\n",
    "```\n",
    "Use `.head()` (first), `.tail()` (last) and `.sample()` (random) to show 5 rows by standard. Increase the amount by passing an argument, for example: `df.head(10)`. <br><br>\n",
    "To figure out the size of the dataframe and what kind of attributes you are dealing with, you can use the `info()` function. Every column in your dataset is turned into a row. For every column some information is displayed like the **Dtype** which is the type of values that are in the column.<br><br>\n",
    "You can find null values (or missing data) based on the amount of non-null cells in each of the columns. Besides that there is some more information displayed like size of the dataset. You can see **RangeIndex: 16719 entries** meaning there are 16719 rows and **Data columns (total 16 columns)** meaning there are 16 columns.<br><br>\n",
    "Use `help()` to get the explaination of methods, like `help(df.info)` .\n",
    "\n",
    "### 2.2 Creating Statistic\n",
    "`describe()` can give you all the statistics in one overview for the **numeric** columns.\n",
    "```python\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "`unique()` can give you all the unique value in a column.\n",
    "```python\n",
    "df['Platform'].unique()\n",
    "# array(['Wii', 'NES', 'GB', 'DS', 'X360', 'PS3', 'PS2', 'SNES', 'GBA',\n",
    "#       'PS4', '3DS', 'N64', 'PS', 'XB', 'PC', '2600', 'PSP', 'XOne',\n",
    "#       'WiiU', 'GC', 'GEN', 'DC', 'PSV', 'SAT', 'SCD', 'WS', 'NG', 'TG16',\n",
    "#       '3DO', 'GG', 'PCFX'], dtype=object)\n",
    "```\n",
    "\n",
    "#### 2.2.1 Mean\n",
    "The average of all the values in the column. Useful for example if you want to know what the average amount of sales is globally. This can be done by using the `mean()` function on the **Global_Sales** column.\n",
    "```python\n",
    "df['Global_Sales'].mean() # 0.5335426759973684\n",
    "```\n",
    "\n",
    "#### 2.2.2 Min and max\n",
    "Getting the lowest value in a column is useful to know because this allows you to get an idea of the range of values together with the maximum value. Use the `min()` adn `max()` functions to get these values.\n",
    "```python\n",
    "print(df['Global_Sales'].min()) # 0.01\n",
    "print(df['Global_Sales'].max()) # 82.53\n",
    "```\n",
    "\n",
    "#### 2.2.3 Median\n",
    "This is the value precisely in at 50% after sorting all value in order from small to large. Meaning about 50% of the data is above and below this value. You can use this to get a better understanding of the average value. Because average might be skewed by extremely high or low values. You can calculate the median by using the `median()` function.\n",
    "```python\n",
    "df['Global_Sales'].median() # 0.17\n",
    "```\n",
    "\n",
    "#### 2.2.4 Std\n",
    "The deviation of each value in the column from the mean, taking the square root of those values and save the results in a list. Calculate the mean for that list of deviations and the take the root. Good to get an idea of the dispersion of the values in a column, you can do this by using the `std()` function.\n",
    "```python\n",
    "df['Critic_Score'].std() # 13.938164552843201\n",
    "```\n",
    "\n",
    "#### 2.2.5 Mode\n",
    "The mode function gives you the most common value in the column. So for example if we would like to see what the most given score is by critics we can do the `mode()` function on the column **Critic_Score**.\n",
    "```python\n",
    "df['Critic_Score'].mode() \n",
    "# 0    70.0\n",
    "# Name: Critic_Score, dtype: float64\n",
    "```\n",
    "\n",
    "\n",
    "### 2.3 Histogram\n",
    "There are hundreds of different graphs available in libraries like **matplotlib**. Here are a few examples: [Matplotlib.org](https://matplotlib.org/stable/plot_types/index) .\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df['Year_of_Release'], bins=20)\n",
    "plt.title('This is the title of the plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## 3 Select Data\n",
    "### 3.1 Using loc()\n",
    "Gather all the Xbox 360 games<br>\n",
    "`df.loc[df[\"Platform\"] == \"X360\"]`<br><br>\n",
    "\n",
    "Find games released on the PS4 and sold more than 1 million copies globally<br>\n",
    "`df.loc[(df[\"Platform\"] == \"PS4\") & (df[\"Global_Sales\"] > 1)]`<br><br>\n",
    "\n",
    "Identify the name and critic score of action games released in 2008 that had a critic score of more than 90<br>\n",
    "`df.loc[(df[\"Genre\"] == \"Action\") & (df[\"Year_of_Release\"] ==2008) & (df[\"Critic_Score\"] > 90), [\"Name\", \"Critic_Score\"]]`<br><br>\n",
    "\n",
    "Identify sports games released between 2000 and 2010 that sold at least 1 million copies in Europe with a user score below 7. Display the name and publisher<br>\n",
    "`df.loc[(df[\"Year_of_Release\"] >= 2000) & (df[\"Year_of_Release\"] <= 2010) & (df[\"Genre\"] == \"Sports\") & (df[\"EU_Sales\"] >= 2) & (df[\"User_Score\"] < 7), [\"Name\", \"Publisher\"]]`<br>\n",
    "\n",
    "### 3.2 Using iloc()\n",
    "`iloc[]` is purely used for integer-location based indexing for selecting by position. In other words, rows or columns are selected based on their location in the dataframe.<br><br>\n",
    "\n",
    "First 4 rows and all the columns<br>\n",
    "`df.iloc[0:4]` or `df.iloc[0:4,:]`<br><br>\n",
    "\n",
    "All the rows and first 4 columnsS<br>\n",
    "`df.iloc[:,0:4]`<br><br>\n",
    "\n",
    "First 4 rows and first 4 columns<br>\n",
    "`df.iloc[0:4,0:4]`<br><br>\n",
    "\n",
    "First 4 rows and third + fourth column<br>\n",
    "`df.iloc[0:4,2:4]`<br><br>\n",
    "\n",
    "Second + third row and third + fourth column<br>\n",
    "`df.iloc[1:3,2:4]`<br><br>\n",
    "\n",
    "Select the 5th to the 10th row and the last three columns<br>\n",
    "`df.iloc[4:9,-3:]`\n",
    "\n",
    "## 4. Benchmark model\n",
    "The dataset contains taxi trips and their cost and some other factors like distance and time of pick up and drop off. It is from Kaggle and can be found [here](https://www.kaggle.com/datasets/denkuznetz/taxi-price-prediction).\n",
    "```python\n",
    "df = pd.read_csv('../taxi_trip_pricing.csv',sep='|')\n",
    "```\n",
    "\n",
    "### 4.1 The Data\n",
    "#### 4.1.1 Business Understanding\n",
    "在开始分析和准备数据之前，我们首先需要知道我们想要实现什么目标。这个目标就是 创建一个能够根据距离和时间预测行程价格的模型。\n",
    "- 输入（features）：行程距离、时间、天气、交通状况等\n",
    "- 输出（target）：行程总费用（Trip_Price）\n",
    "- 最终目标：让模型学会从输入数据中预测车费\n",
    "\n",
    "#### 4.1.2 Data Understanding\n",
    "Take a look at the data to get a better understanding of what we are working with\n",
    "```python\n",
    "df.head(1)\n",
    "df.info()\n",
    "df.describe()\n",
    "```\n",
    "Some context to get a better understanding of what each of the columns mean:\n",
    "* **Trip_Distance_km**: The total distance of the trip 行程的总距离（公里）\n",
    "* **Time_of_Day**: The time of day at the point of the trip 行程开始的时间\n",
    "* **Day_of_Week**: Day of the week the trip was taken 行程的星期几\n",
    "* **Passenger_Count**: The amount of passengers in the taxi 乘客人数\n",
    "* **Traffic_Conditions**: The conditions of the traffick during the trip 交通状况\n",
    "* **Base_Fare**: The base cost of the taxi 出租车的基本费用\n",
    "* **Weather**: The weather conditions during the trip 天气状况\n",
    "* **Per_Km_Rate**: The cost per kilometer 每公里收费\n",
    "* **Per_Minute_Rate**: The cost per minute 每分钟收费\n",
    "* **Trip_Duration_Minutes**: The total duration of the trip in minutes 行程持续时间（分钟）\n",
    "* **Trip_Price**: The total price of the trip 目标变量（总价格）\n",
    "\n",
    "#### 4.1.3 Data Preperation\n",
    "在本课中，我们将放弃所有包含缺失值的行，而不是进行复杂的估算。为此，我们使用 dropna 函数。在该函数中，调用 inplace 参数并将其设置为 True，这将用不含缺失值的数据覆盖我们现有的名为 df 的数据。\n",
    "```python\n",
    "df.dropna(inplace=True) # 先把所有有缺失值的行去掉，以免影响模型训练。\n",
    "```\n",
    "\n",
    "### 4.2 Test Design\n",
    "#### 4.2.1 Splitting data\n",
    "To split the data we will be using a function called [**train_test_split**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from **Sklean**.<br><br>\n",
    "在构建模型前，我们需要把数据分成 训练集 和 测试集：\n",
    "- 训练集（train set）：用于训练模型\n",
    "- 测试集（test set）：用于评估模型性能\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n",
    "Split the data into a train and test set\n",
    "```python\n",
    "# pop() can be used to extract a column from the dataframe and remove it from the dataframe at the same time\n",
    "\n",
    "# target is called y a lot in documentation 目标变量（y）：车费\n",
    "target = dfx.pop('Trip_Price')\n",
    "\n",
    "# features is called X a lot in documentation 特征（X）：其余所有列\n",
    "features = dfx\n",
    "\n",
    "# 拆分数据集（75% 训练集，25% 测试集）; random_state=42：保证每次运行拆分出的数据相同\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "\n",
    "print('The length of y_train is:', len(y_train)) # The length of y_train is: 421 训练集样本数\n",
    "print('The length of y_test is:', len(y_test)) # The length of y_test is: 141 测试集样本数\n",
    "```\n",
    "\n",
    "#### 4.2.2 The Benchmark\n",
    "为了判断未来的模型是否有效，我们先构造一个最简单的基准模型：\n",
    "- 思路：让模型 始终预测训练集车费的平均值。\n",
    "- 目标：后续的模型 必须比这个基准模型更准确。\n",
    "\n",
    "```python\n",
    "\"\"\" \n",
    "len() is used to get the length of an object, if the object is a series/list than it will return the number of elements it contains. If it is a \n",
    "string it will give the number of characters\n",
    "\"\"\"\n",
    "value = y_train.mean() # 计算 y_train（训练集的车费）的平均值\n",
    "\n",
    "pred_train = [value] * len(y_train) # 让所有样本的预测值都等于这个均值\n",
    "pred_test = [value] * len(y_test) # 让所有样本的预测值都等于这个均值\n",
    "```\n",
    "\n",
    "#### 4.2.3 Metric\n",
    "MAE（均值绝对误差） 计算预测值与真实值的平均绝对差距，作用是衡量模型预测的误差（值越小越好）。\n",
    "```python\n",
    "# Import the Mean Absolute Error from the library\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print('MAE of train set:', mean_absolute_error(pred_train, y_train))\n",
    "print('MAE of test set:', mean_absolute_error(pred_test, y_test))\n",
    "```\n",
    "还可以计算和输出RMSE:\n",
    "```python\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "\n",
    "print(f\"Train MAE: {mae_train:.2f}, Train RMSE: {rmse_train:.2f}\")\n",
    "print(f\"Test MAE: {mae_test:.2f}, Test RMSE: {rmse_test:.2f}\")\n",
    "```\n",
    "\n",
    "## 5. Merging and Visualizing Data\n",
    "### 5.1 Merging\n",
    "Load both datasets into separate dataframes, then use `head()` to check the column names\n",
    "```python\n",
    "df_games = pd.read_csv('videogames.csv', sep=';')\n",
    "console_data = pd.read_csv('console-dataset.csv',sep='|')\n",
    "df_games.head(5)\n",
    "console_data.head(5)\n",
    "```\n",
    "Choose a merging type from `Inner, left, right, full`\n",
    "```python\n",
    "df_merged = df_games.merge(console_data, left_on='Platform', right_on='Console Name', how='outer')\n",
    "```\n",
    "\n",
    "### 5.2 Visualizing data\n",
    "#### 5.2.1 Barplot\n",
    "A bar plot is a graphical representation of categorical data using bars of different heights. Bar plots are used to compare the frequency, count, or any other measurable value across different categories. 条形图是使用不同高度的条形来表示分类数据的图形。条形图用于比较不同类别的频率、计数或任何其他可测量值。<br>\n",
    "Let's start with using value_counts() on a specific column before we create a bar plot with `.plot.bar()`. 在使用 `.plot.bar()` 创建条形图之前，我们先在特定列上使用 `value_counts()`。\n",
    "```python\n",
    "df_merged['Platform'].value_counts()\n",
    "```\n",
    "```python\n",
    "plt.figure(figsize=(10,6))\n",
    "df_merged['Platform'].value_counts().plot.bar(color='pink')\n",
    "plt.xlabel('Platform',fontsize=10)\n",
    "plt.ylabel('Amount of games releases',fontsize=10)\n",
    "plt.title(\"Amount of games releasesd per platform\")\n",
    "plt.xticks(ha=\"right\",rotation=60,fontsize=8)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 5.2.2 Lineplot\n",
    "```python\n",
    "df_merged['Year_of_Release'].value_counts().sort_values().sort_index().plot.line()\n",
    "```\n",
    "\n",
    "#### 5.2.3 Scatterplot\n",
    "A scatterplot is a type of graph that displays the relationship between two numerical variables. In a scatterplot, each point on the graph represents a single datapoint. They are particularly useful for identifying correlations between variables, detecting patterns, and visualizing the spread of data. 散点图是一种显示两个数字变量之间关系的图表。在散点图中，图上的每个点代表一个数据点。散点图对于确定变量之间的相关性、发现模式和直观显示数据的分布特别有用。\n",
    "```python\n",
    "plt.xlabel('Consoles sold')\n",
    "plt.ylabel('Global Sales')\n",
    "plt.title('Global sales of a game compared to the number of consoles sold')\n",
    "plt.scatter(df_merged['Units sold (million)'], df_merged['Global_Sales'])\n",
    "```\n",
    "\n",
    "#### 5.2.4 Seaborn\n",
    "Seaborn is a Python library built on top of matplotlib, known for its elegant and informative statistical graphics. With seaborn, we can easily create visually appealing plots with minimal code, making complex visualizations accessible to everyone. But ofcourse before we can use the library we need to install it and then import it in out notebook.\n",
    "```python\n",
    "import seaborn as sns\n",
    "```\n",
    "You can read more about the possibility of seaborn on their website [here](https://seaborn.pydata.org/index.html).<br>\n",
    "统计 `df_merged` 数据集中每个平台（Platform）上的游戏数量，并用柱状图（barplot）展示。`value_counts()` 计算每个平台的游戏数量。这个图可以帮助观察 不同类型的游戏销量 是否有明显的模式，比如某些类型的游戏是否更畅销。\n",
    "```python\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(df_merged['Platform'].value_counts()) # 画出不同游戏平台的游戏数量\n",
    "plt.xlabel('Platform',fontsize=10)\n",
    "plt.ylabel('Count',fontsize=10)\n",
    "plt.title(\"Diagram\")\n",
    "plt.xticks(ha=\"right\",rotation=60,fontsize=8) # x 轴刻度标签旋转 60 度，靠右对齐\n",
    "plt.show()\n",
    "```\n",
    "画出每款游戏的销量数据，横轴是 \"Units sold (million)\"（销量），纵轴是 \"Global_Sales\"（全球总销量）。用不同颜色区分游戏类型（Genre）\n",
    "```python\n",
    "sns.scatterplot(data=df_merged, x='Units sold (million)', y='Global_Sales',hue='Genre')\n",
    "```\n",
    "画出不同类型游戏（Genre）的平均评分随时间变化的趋势。`estimator='mean'` 计算每年的平均评分。这个图可以帮助观察游戏评分在不同时期是否有下降或上升趋势，不同类型的游戏评分是否有明显差异。\n",
    "```python\n",
    "sns.lineplot(data=df_merged, x='Year_of_Release',\n",
    "            y='Critic_Score', estimator='mean', errorbar=('ci',False),hue='Genre')\n",
    "```\n",
    "折线图 总体评分趋势。和上面类似，但没有 `hue='Genre'`，所以它展示的是所有游戏的评分趋势。这有助于了解游戏评分的总体变化，而不关注特定类型。\n",
    "```python\n",
    "sns.lineplot(data=df_merged, x='Year_of_Release',\n",
    "            y='Critic_Score', estimator='mean', errorbar=('ci',False))\n",
    "```\n",
    "折线图 体育类 vs 赛车类游戏的评分趋势。只选出 体育类（Sports） 和 赛车类（Racing） 的游戏，画出它们的 平均评分随时间的变化。这个图可以用于比较体育游戏 vs 赛车游戏的评分变化，哪个类型的评分更高；评分是否有 下降或上升趋势。\n",
    "```python\n",
    "df_ = df_merged.loc[(df_merged['Genre']=='Sports') | (df_merged['Genre'] == 'Racing')]\n",
    "sns.lineplot(data=df_, x='Year_of_Release',\n",
    "            y='Critic_Score', estimator='mean', errorbar=('ci',False),hue='Genre')\n",
    "``` \n",
    "Create a lineplot that shows the amount games sold per year，统计每年的游戏全球销售总额。<br>\n",
    "`estimator='sum'` 代表每年的销量求和。这个图可以观察游戏行业的销售趋势（比如是否存在巅峰时期），哪些年份的总销售额最高。\n",
    "```python\n",
    "sns.lineplot(data=df_merged, x='Year_of_Release',\n",
    "            y='Global_Sales', estimator='sum', errorbar=('ci',False))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
